{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word embedding classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "kgteJ1Iz7zur",
        "LBBTmoha-GaM",
        "JEo8ohuz-sCg"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/inpaner/nlp-ml/blob/master/Word_embedding_classification.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "kgteJ1Iz7zur",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Word Embeddings"
      ]
    },
    {
      "metadata": {
        "id": "ThAhvDco0Li8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "np.set_printoptions(precision=4, suppress=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_SW2NzVaQ-Qz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget -nc http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -p glove.6B.zip glove.6B.50d.txt > glove.6B.50d.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g5jx6fnfRkeS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "def load_embeddings(file_name, dimensions):\n",
        "  words = []\n",
        "  vecs = []\n",
        "    \n",
        "  with codecs.open(file_name, 'r', 'utf-8', errors='ignore') as f:\n",
        "    for count, line in enumerate(f):\n",
        "      values = line.split()\n",
        "      if count % 100000 == 0 and count != 0:\n",
        "          print('loaded {} embeddings'.format(count))\n",
        "            \n",
        "      if len(values[1:]) != 50:\n",
        "          continue\n",
        "\n",
        "      try:\n",
        "          word = values[0]\n",
        "          vec = np.asarray(values[1:], dtype=np.float32)\n",
        "          words.append(word)\n",
        "          vecs.append(vec)\n",
        "      except Error as e:\n",
        "          continue\n",
        "  \n",
        "  print(len(words), len(vecs))\n",
        "  assert len(words) == len(vecs)\n",
        "  np_vecs = np.stack(vecs)\n",
        "  wordidx = {o: i for i, o in enumerate(words)}\n",
        "  return words, np_vecs, wordidx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UC_xwgr4SeB2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words, vecs, wordidx = load_embeddings('glove.6B.50d.txt', 50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rFt-NBNxS1f9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RzGm580VTdm9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kk58L9VzTeqZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words[600:610]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HDTeXHEbTjRC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wordidx['cow']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GvraO-B4Tmzx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words[6472]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxCED-bWTpC7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vecs[6472]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gxGnrGjjTsYC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_to_vec = {}\n",
        "for word, vec in zip(words, vecs):\n",
        "  word_to_vec[word] = vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ntSYpMZT4No",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_to_vec['cow']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z9zs3lAgT65Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine as dist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YlvxlRMn8WIU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dist(word_to_vec['president'], word_to_vec['obama'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CBD39FYo8jnP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dist(word_to_vec['president'], word_to_vec['trump'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JcZ1oo6lT-Of",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dist(word_to_vec['man'], word_to_vec['genius'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ImFQkr7UF_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dist(word_to_vec['woman'], word_to_vec['genius'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9OumRAPAW6db",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "neighbors = NearestNeighbors(n_neighbors=10, radius=0.5, metric='cosine', algorithm='brute')\n",
        "neighbors.fit(vecs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oBZ_eABxW_PR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def find_nearest(vector):\n",
        "  distances, indices = neighbors.kneighbors([vector])\n",
        "  return [(words[int(index)], distance) for index, distance in zip(list(indices[0]), list(distances[0]))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a5Xcr2QeXDK2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "find_nearest(word_to_vec[\"frog\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8wves8qu9iLk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "find_nearest(word_to_vec[\"artificial\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yKFbXgN69h-A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "find_nearest(word_to_vec[\"intelligence\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P0MG6uecXYnC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_vec = (word_to_vec['artificial'] + word_to_vec['intelligence'])/2\n",
        "find_nearest(new_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L1M6bpvZYp_B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "find_nearest(word_to_vec['king'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pnbp7XqZXmLU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_vec = word_to_vec['king'] - word_to_vec['man'] + word_to_vec['woman']\n",
        "find_nearest(new_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wy5agvK6Yfxc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_vec = word_to_vec['philippines'] - word_to_vec['manila'] + word_to_vec['paris']\n",
        "find_nearest(new_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LBBTmoha-GaM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ]
    },
    {
      "metadata": {
        "id": "F8L6WXMiZAnF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.utils.data_utils import get_file\n",
        "idx = imdb.get_word_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sa8nSC5xZhKY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def limit_mem():\n",
        "    K.get_session().close()\n",
        "    cfg = K.tf.ConfigProto()\n",
        "    cfg.gpu_options.allow_growth = True\n",
        "    cfg.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
        "    K.set_session(K.tf.Session(config=cfg))\n",
        "    \n",
        "limit_mem()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AUCoyRIGZlrG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx_arr = sorted(idx, key=idx.get)\n",
        "idx2word = {v: k for k, v in idx.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ixzQeGjqZn7W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = get_file('imdb_full.pkl',\n",
        "                origin='https://s3.amazonaws.com/text-datasets/imdb_full.pkl',\n",
        "                md5_hash='d091312047c43cf9e4e38fef92437263')\n",
        "f = open(path, 'rb')\n",
        "(x_train, labels_train), (x_test, labels_test) = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y9HXbHCTZxXt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_size = 5000\n",
        "\n",
        "trn = [np.array([i if i<vocab_size-1 else vocab_size-1 for i in s]) for s in x_train]\n",
        "test = [np.array([i if i<vocab_size-1 else vocab_size-1 for i in s]) for s in x_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wlbgEfT2Z1br",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lens = np.array([len(review) for review in trn])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uzwb6vH_Z4l0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(lens.max(), lens.min(), lens.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q-b2viYmazFJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence\n",
        "\n",
        "\n",
        "seq_len = 500\n",
        "trn = sequence.pad_sequences(trn, maxlen=seq_len, value=0)\n",
        "test = sequence.pad_sequences(test, maxlen=seq_len, value=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JEo8ohuz-sCg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural network"
      ]
    },
    {
      "metadata": {
        "id": "3ppVslu7a_aO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.core import Flatten, Dense, Dropout, SpatialDropout1D\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JL9b9bNgbJIA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_emb():\n",
        "    n_fact = vecs.shape[1]\n",
        "    emb = np.zeros((vocab_size, n_fact))\n",
        "\n",
        "    for i in range(1,len(emb)):\n",
        "        word = idx2word[i]\n",
        "        if word and re.match(r\"^[a-zA-Z0-9\\-]*$\", word):\n",
        "            src_idx = wordidx[word]\n",
        "            emb[i] = vecs[src_idx]\n",
        "        else:\n",
        "            emb[i] = np.random.normal(scale=0.6, size=(n_fact,))\n",
        "\n",
        "    emb[-1] = np.random.normal(scale=0.6, size=(n_fact,))\n",
        "    emb/=3\n",
        "    return emb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "79Xp9yz_bbe1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emb = create_emb()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b62__2stdBO9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(vocab_size, 50, input_length=seq_len, weights=[emb]),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mmhjd3Tvbp5m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZNHvdCAFb9mr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(trn, labels_train, validation_data=(test, labels_test), epochs=2, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1QfCwzKTb_Wv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(vocab_size, 50, input_length=seq_len, weights=[emb]),\n",
        "    SpatialDropout1D(0.4),\n",
        "    Conv1D(64, 5, padding='same', activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    MaxPooling1D(),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')])\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "model.fit(trn, labels_train, validation_data=(test, labels_test), epochs=2, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BAPqNiW96Spb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "4cae9e35-c82a-4866-d53c-185a6ffca95e"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 42,
      "outputs": []
    }
  ]
}